"""
å†…å®¹æå–å™¨æ¼”ç¤ºè„šæœ¬

ç‹¬ç«‹è¿è¡Œçš„ Demoï¼Œç”¨äºæµ‹è¯•å†…å®¹æå–åŠŸèƒ½
"""

import sys
import os
import csv
import json
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from auto.extractor import JinaExtractor, BrowserExtractor, ExtractedContent


def load_urls_from_file(file_path: str) -> list[str]:
    """
    ä»æ–‡ä»¶åŠ è½½ URL åˆ—è¡¨
    
    æ”¯æŒæ ¼å¼ï¼š
    - .txt: æ¯è¡Œä¸€ä¸ª URL
    - .csv: æ”¯æŒå¤šåˆ—ï¼Œè‡ªåŠ¨è¯†åˆ« URL åˆ—
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        list[str]: URL åˆ—è¡¨
    """
    urls = []
    file_path = Path(file_path)
    
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return urls
    
    try:
        urls = load_urls_from_csv(file_path)
        
        print(f"âœ… ä» {file_path.name} åŠ è½½äº† {len(urls)} ä¸ª URL")
        return urls
    
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return []

def load_urls_from_csv(file_path: Path) -> list[str]:
    """
    ä» CSV æ–‡ä»¶åŠ è½½ URL
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    1. å•åˆ— CSVï¼ˆåªæœ‰ URLï¼‰
    2. å¤šåˆ— CSVï¼ˆè‡ªåŠ¨è¯†åˆ«åŒ…å« 'url' æˆ– 'link' çš„åˆ—ï¼‰
    3. å¸¦è¡¨å¤´çš„ CSV
    4. æ— è¡¨å¤´çš„ CSVï¼ˆå–ç¬¬ä¸€åˆ—ï¼‰
    """
    urls = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        # å°è¯•æ£€æµ‹ CSV æ ¼å¼
        sample = f.read(1024)
        f.seek(0)
        
        # æ£€æµ‹åˆ†éš”ç¬¦
        sniffer = csv.Sniffer()
        try:
            dialect = sniffer.sniff(sample)
            has_header = sniffer.has_header(sample)
        except:
            dialect = 'excel'
            has_header = False
        
        reader = csv.reader(f, dialect)
        rows = list(reader)
        
        if not rows:
            return urls
        
        # å¦‚æœæœ‰è¡¨å¤´ï¼ŒæŸ¥æ‰¾ URL åˆ—
        if has_header:
            headers = [h.lower().strip() for h in rows[0]]
            url_col_index = None
            
            # æŸ¥æ‰¾åŒ…å« 'url' æˆ– 'link' çš„åˆ—
            for i, header in enumerate(headers):
                if 'url' in header or 'link' in header:
                    url_col_index = i
                    break
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—
            if url_col_index is None:
                url_col_index = 0
            
            # æå– URL
            for row in rows[1:]:
                if len(row) > url_col_index:
                    url = row[url_col_index].strip()
                    if url and url.startswith('http'):
                        urls.append(url)
        else:
            # æ— è¡¨å¤´ï¼Œå–ç¬¬ä¸€åˆ—
            for row in rows:
                if row:
                    url = row[0].strip()
                    if url and url.startswith('http'):
                        urls.append(url)
    
    return urls

def save_results_to_json(results: list, output_file: str):
    """
    ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶

    Args:
        results: æå–ç»“æœåˆ—è¡¨
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    try:
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data = [result.to_dict() for result in results]

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"\nâŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

def save_results_to_markdown(results: list, output_file: str):
    """
    ä¿å­˜ç»“æœåˆ° Markdown æ–‡ä»¶
    
    Args:
        results: æå–ç»“æœåˆ—è¡¨
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# å†…å®¹æå–ç»“æœ\n\n")
            f.write(f"æ€»è®¡: {len(results)} ä¸ªé“¾æ¥\n\n")
            f.write("---\n\n")
            
            for i, result in enumerate(results, 1):
                f.write(f"## {i}. {result.title}\n\n")
                f.write(f"- **URL**: {result.url}\n")
                f.write(f"- **å¹³å°**: {result.platform}\n")
                f.write(f"- **å­—æ•°**: {result.word_count}\n")
                f.write(f"- **çŠ¶æ€**: {'âœ“ æˆåŠŸ' if result.success else f'âœ— å¤±è´¥: {result.error}'}\n")
                
                if result.author:
                    f.write(f"- **ä½œè€…**: {result.author}\n")
                if result.publish_date:
                    f.write(f"- **å‘å¸ƒæ—¥æœŸ**: {result.publish_date}\n")
                
                f.write(f"- **æå–æ—¶é—´**: {result.extract_time}\n\n")
                
                if result.success and result.content:
                    f.write("### å†…å®¹é¢„è§ˆ\n\n")
                    # åªæ˜¾ç¤ºå‰ 500 å­—ç¬¦
                    preview = result.content[:500]
                    if len(result.content) > 500:
                        preview += "\n\n...(å†…å®¹è¿‡é•¿ï¼Œå·²çœç•¥)..."
                    f.write(f"{preview}\n\n")
                
                f.write("---\n\n")
        
        print(f"âœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

def print_summary(results: list):
    """
    æ‰“å°ç»Ÿè®¡æ‘˜è¦
    
    Args:
        results: æå–ç»“æœåˆ—è¡¨
    """
    total = len(results)
    success = sum(1 for r in results if r.success)
    failed = total - success
    
    total_words = sum(r.word_count for r in results if r.success)
    avg_words = total_words // success if success > 0 else 0
    
    print("\n" + "="*60)
    print("ğŸ“Š æå–ç»Ÿè®¡")
    print("="*60)
    print(f"æ€»è®¡: {total} ä¸ªé“¾æ¥")
    print(f"æˆåŠŸ: {success} ä¸ª ({success/total*100:.1f}%)")
    print(f"å¤±è´¥: {failed} ä¸ª ({failed/total*100:.1f}%)")
    print(f"æ€»å­—æ•°: {total_words:,} å­—")
    print(f"å¹³å‡å­—æ•°: {avg_words:,} å­—/ç¯‡")
    print("="*60)

def print_result(result: ExtractedContent):
    """
    æ‰“å°æå–ç»“æœ
    
    Args:
        result: æå–ç»“æœå¯¹è±¡
    """
    print("\n" + "-"*60)
    print("ğŸ“„ æå–ç»“æœ")
    print("-"*60)
    print(f"æ ‡é¢˜: {result.title}")
    print(f"å¹³å°: {result.platform}")
    print(f"Logo: {result.platform_logo}")
    print(f"å­—æ•°: {result.word_count}")
    print(f"çŠ¶æ€: {'âœ“ æˆåŠŸ' if result.success else f'âœ— å¤±è´¥: {result.error}'}")
    
    if result.author:
        print(f"ä½œè€…: {result.author}")
    if result.publish_date:
        print(f"å‘å¸ƒæ—¥æœŸ: {result.publish_date}")
    
    print(f"æå–æ—¶é—´: {result.extract_time}")
    
    if result.processing_time is not None:
        print(f"å¤„ç†è€—æ—¶: {result.processing_time:.2f} ç§’")
    
    if result.success and result.content:
        print("\nå†…å®¹é¢„è§ˆ:")
        print("-"*60)
        preview = result.content[:300]
        if len(result.content) > 300:
            preview += "\n...(å†…å®¹è¿‡é•¿ï¼Œå·²çœç•¥)..."
        print(preview)
    
    print("-"*60)

def test_single_url():
    """æµ‹è¯•å•ä¸ª URL"""
    print("\n" + "="*60)
    print("ğŸ” å•ä¸ª URL æµ‹è¯•")
    print("="*60)
    
    url = input("\nè¯·è¾“å…¥è¦æµ‹è¯•çš„ URL: ").strip()
    
    if not url:
        print("âŒ URL ä¸èƒ½ä¸ºç©º")
        return
    
    print("\né€‰æ‹©æå–å™¨:")
    print("1. Jina æå–å™¨ï¼ˆæ¨èï¼‰")
    print("2. æµè§ˆå™¨æå–å™¨")
    
    choice = input("\nè¯·é€‰æ‹© (1-2): ").strip()
    
    if choice == "1":
        print("\nâ³ ä½¿ç”¨ Jina æå–å™¨...")
        extractor = JinaExtractor(timeout=30, api_key="jina_beda6e0b116a48aab8c13f6f0ed2a0c0synZFaRRgP1mXAgbxDdGsbxTZ1qm")
        result = extractor.extract(url)
        print_result(result)
    
    elif choice == "2":
        print("\nâ³ ä½¿ç”¨æµè§ˆå™¨æå–å™¨...")
        with BrowserExtractor(headless=False) as extractor:
            result = extractor.extract(url)
            print_result(result)
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

def save_single_result(result: ExtractedContent, index: int, output_dir: Path):
    """
    ä¿å­˜å•ä¸ªæå–ç»“æœåˆ°æ–‡ä»¶
    
    Args:
        result: æå–ç»“æœå¯¹è±¡
        index: åºå·
        output_dir: è¾“å‡ºç›®å½•
    """
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨åºå·å’Œæ ‡é¢˜çš„å‰20ä¸ªå­—ç¬¦ï¼‰
        safe_title = "".join(c for c in result.title[:20] if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_title = safe_title.replace(' ', '_')
        
        if not safe_title:
            safe_title = f"article_{index}"
        
        filename_base = f"{index:03d}_{safe_title}"
        
        # ä¿å­˜ JSON æ ¼å¼
        json_file = output_dir / f"{filename_base}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(result.to_dict(), f, ensure_ascii=False, indent=2)
            f.flush()  # ç«‹å³åˆ·æ–°ç¼“å†²åŒº
            os.fsync(f.fileno())  # å¼ºåˆ¶å†™å…¥ç£ç›˜
        
        # ä¿å­˜ Markdown æ ¼å¼
        md_file = output_dir / f"{filename_base}.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(f"# {result.title}\n\n")
            f.write(f"- **URL**: {result.url}\n")
            f.write(f"- **å¹³å°**: {result.platform}\n")
            f.write(f"- **å­—æ•°**: {result.word_count}\n")
            f.write(f"- **çŠ¶æ€**: {'âœ“ æˆåŠŸ' if result.success else f'âœ— å¤±è´¥: {result.error}'}\n")
            
            if result.author:
                f.write(f"- **ä½œè€…**: {result.author}\n")
            if result.publish_date:
                f.write(f"- **å‘å¸ƒæ—¥æœŸ**: {result.publish_date}\n")
            
            f.write(f"- **æå–æ—¶é—´**: {result.extract_time}\n")
            
            if result.processing_time is not None:
                f.write(f"- **å¤„ç†è€—æ—¶**: {result.processing_time:.2f} ç§’\n")
            
            f.write("\n")
            
            if result.success and result.content:
                f.write("## æ­£æ–‡å†…å®¹\n\n")
                f.write(result.content)
            
            f.flush()  # ç«‹å³åˆ·æ–°ç¼“å†²åŒº
            os.fsync(f.fileno())  # å¼ºåˆ¶å†™å…¥ç£ç›˜
        
        print(f"  âœ“ å·²ä¿å­˜: {json_file.name} å’Œ {md_file.name}")
        
    except Exception as e:
        print(f"  âŒ ä¿å­˜å¤±è´¥: {e}")

def test_batch_urls():
    """æ‰¹é‡æµ‹è¯• URL"""
    print("\n" + "="*60)
    print("ğŸ“¦ æ‰¹é‡ URL æµ‹è¯•")
    print("="*60)
    
    # è·å–æ–‡ä»¶è·¯å¾„
    print("\næ”¯æŒçš„æ–‡ä»¶æ ¼å¼:")
    print("  - test_urls.txt (é»˜è®¤)")
    print("  - url.csv")
    print("  - æˆ–è¾“å…¥è‡ªå®šä¹‰æ–‡ä»¶è·¯å¾„")
    
    file_path = input("\nè¯·è¾“å…¥æ–‡ä»¶è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨ test_urls.txt): ").strip()
    
    if not file_path:
        file_path = "test_urls.txt"
    
    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    if not os.path.isabs(file_path):
        file_path = os.path.join(os.path.dirname(__file__), file_path)
    
    # åŠ è½½ URL
    urls = load_urls_from_file(file_path)
    
    if not urls:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ URL")
        return
    
    # é€‰æ‹©æå–å™¨
    print("\né€‰æ‹©æå–å™¨:")
    print("1. Jina æå–å™¨ï¼ˆæ¨èï¼‰")
    print("2. æµè§ˆå™¨æå–å™¨")
    
    choice = input("\nè¯·é€‰æ‹© (1-2): ").strip()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent / "output"
    output_dir.mkdir(exist_ok=True)
    
    # ç”¨äºç»Ÿè®¡
    results = []
    
    if choice == "1":
        # è·å– API Key
        api_key = input("\nè¯·è¾“å…¥ Jina API Key (ç›´æ¥å›è½¦è·³è¿‡): ").strip() or None
        
        print(f"\nâ³ ä½¿ç”¨ Jina æå–å™¨å¤„ç† {len(urls)} ä¸ª URL...")
        print(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {output_dir}\n")
        extractor = JinaExtractor(timeout=30, api_key=api_key)
        
        for i, url in enumerate(urls, 1):
            print(f"\n{'='*60}")
            print(f"ğŸ“ [{i}/{len(urls)}] {url}")
            print('='*60)
            
            # å¼€å§‹è®¡æ—¶
            start_time = time.time()
            
            result = extractor.extract(url)
            
            # è®¡ç®—è€—æ—¶
            end_time = time.time()
            processing_time = end_time - start_time
            result.processing_time = processing_time
            
            print_result(result)
            
            # ç«‹å³ä¿å­˜ç»“æœ
            save_single_result(result, i, output_dir)
            results.append(result)
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            if i < len(urls):
                time.sleep(2)
    
    elif choice == "2":
        print(f"\nâ³ ä½¿ç”¨æµè§ˆå™¨æå–å™¨å¤„ç† {len(urls)} ä¸ª URL...")
        print(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {output_dir}\n")
        
        with BrowserExtractor(headless=False) as extractor:
            for i, url in enumerate(urls, 1):
                print(f"\n{'='*60}")
                print(f"ğŸ“ [{i}/{len(urls)}] {url}")
                print('='*60)
                
                # å¼€å§‹è®¡æ—¶
                start_time = time.time()
                
                result = extractor.extract(url)
                
                # è®¡ç®—è€—æ—¶
                end_time = time.time()
                processing_time = end_time - start_time
                result.processing_time = processing_time
                
                print_result(result)
                
                # ç«‹å³ä¿å­˜ç»“æœ
                save_single_result(result, i, output_dir)
                results.append(result)
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return
    
    # æ‰“å°ç»Ÿè®¡æ‘˜è¦
    if results:
        print_summary(results)
        print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        print(f"   - JSON æ–‡ä»¶: {len(results)} ä¸ª")
        print(f"   - Markdown æ–‡ä»¶: {len(results)} ä¸ª")

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸš€ å†…å®¹æå–å™¨æ¼”ç¤ºç¨‹åº")
    print("="*60)
    
    while True:
        print("\nè¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
        print("1. å•ä¸ª URL æµ‹è¯•")
        print("2. æ‰¹é‡ URL æµ‹è¯•ï¼ˆæ”¯æŒ TXT/CSVï¼‰")
        print("0. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹© (0-5): ").strip()
        
        if choice == "0":
            print("\nç»“æŸ")
            break

        elif choice == "1":
            test_single_url()
        
        elif choice == "2":
            test_batch_urls()
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        continue_test = input("\næ˜¯å¦ç»§ç»­æµ‹è¯•ï¼Ÿ(y/n): ").strip().lower()
        if continue_test != 'y':
            print("\nğŸ‘‹ å†è§ï¼")
            break


if __name__ == "__main__":
    main()